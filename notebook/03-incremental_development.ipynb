{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492919d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 10:56:42.519316: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-14 10:56:42.519441: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-14 10:56:42.553479: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-14 10:56:42.623110: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "import models\n",
    "import metricsUtils\n",
    "import dataUtils\n",
    "import config\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a25187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(dataset_dir):\n",
    "    dataset = tf.data.Dataset.load(dataset_dir)\n",
    "    classes = ['1_Pronacio', '2_Neutralis', '3_Szupinacio']\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # string -> index TF-ben\n",
    "    lookup_table = tf.lookup.StaticHashTable(\n",
    "        tf.lookup.KeyValueTensorInitializer(\n",
    "            keys=tf.constant(classes),\n",
    "            values=tf.constant(list(range(num_classes)), dtype=tf.int32),\n",
    "        ),\n",
    "        default_value=-1\n",
    "    )\n",
    "\n",
    "    def encode_one_hot_tf(x, y):\n",
    "        y_idx = lookup_table.lookup(y)            # tf.string -> int\n",
    "        y_one_hot = tf.one_hot(y_idx, depth=num_classes)\n",
    "        shape = config.TARGET_IMAGE_SIZE + (3,)\n",
    "        x.set_shape(shape)                  # fix input shape\n",
    "        return x, y_one_hot\n",
    "\n",
    "    dataset = dataset.map(encode_one_hot_tf)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bab9ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 10:56:47.810487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-14 10:56:47.858752: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-14 10:56:47.858819: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-14 10:56:47.862477: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-14 10:56:47.862558: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-14 10:56:47.862593: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-14 10:56:48.097762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-14 10:56:48.097867: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-14 10:56:48.097879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-12-14 10:56:48.097935: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-14 10:56:48.097975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2244 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:10:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "dataset = getData(config.DATA_DIR+\"/dataset\")\n",
    "train_dataset, val_dataset, test_dataset = dataUtils.split_dataset(dataset, config.BATCH_SIZE, config.TRAINING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a07019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel = models.baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154944fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel = models.baseline_model()\n",
    "y_true = []\n",
    "baselinePredictions = []\n",
    "for x, y in train_dataset:\n",
    "    for index in range(len(x)):        \n",
    "        baselinePredictions.append(baselineModel())\n",
    "        y_true.append(y[index])\n",
    "y_true = np.array(y_true)\n",
    "np_baselinePredictions = np.array(baselinePredictions, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961b47a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4252336448598131,\n",
       " 'precision_macro': 0.14174454828660435,\n",
       " 'recall_macro': 0.3333333333333333,\n",
       " 'f1_macro': 0.19890710382513663,\n",
       " 'confusion_matrix': array([[ 0, 88,  0],\n",
       "        [ 0, 91,  0],\n",
       "        [ 0, 35,  0]]),\n",
       " 'classification_report': {'1_Pronacio': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 88.0},\n",
       "  '2_Neutralis': {'precision': 0.4252336448598131,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5967213114754099,\n",
       "   'support': 91.0},\n",
       "  '3_Szupinacio': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 35.0},\n",
       "  'accuracy': 0.4252336448598131,\n",
       "  'macro avg': {'precision': 0.14174454828660435,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.19890710382513663,\n",
       "   'support': 214.0},\n",
       "  'weighted avg': {'precision': 0.18082365272076165,\n",
       "   'recall': 0.4252336448598131,\n",
       "   'f1-score': 0.25374597824421635,\n",
       "   'support': 214.0}},\n",
       " 'roc': {'fpr': {0: array([0., 1.]),\n",
       "   1: array([0., 1.]),\n",
       "   2: array([0., 1.]),\n",
       "   'micro': array([0.        , 0.28738318, 1.        ])},\n",
       "  'tpr': {0: array([0., 1.]),\n",
       "   1: array([0., 1.]),\n",
       "   2: array([0., 1.]),\n",
       "   'micro': array([0.        , 0.42523364, 1.        ])},\n",
       "  'auc': {0: 0.5, 1: 0.5, 2: 0.5, 'micro': 0.5689252336448598, 'macro': 0.5}},\n",
       " 'errors': array([  0,   1,   2,   3,   4,  13,  14,  15,  17,  20,  22,  25,  26,\n",
       "         29,  30,  31,  32,  33,  35,  36,  37,  39,  40,  41,  44,  45,\n",
       "         49,  50,  51,  52,  54,  55,  59,  60,  61,  62,  63,  64,  65,\n",
       "         66,  69,  72,  73,  74,  77,  78,  80,  82,  84,  86,  87,  88,\n",
       "         89,  90,  91,  94,  97,  98, 103, 105, 107, 110, 111, 114, 116,\n",
       "        117, 121, 122, 125, 126, 128, 129, 130, 131, 136, 137, 140, 141,\n",
       "        142, 146, 147, 148, 149, 151, 152, 157, 158, 162, 163, 164, 166,\n",
       "        167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 181, 184, 185,\n",
       "        188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 202, 203, 205,\n",
       "        206, 207, 208, 209, 212, 213]),\n",
       " 'num_errors': 123,\n",
       " 'num_samples': 214}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = metricsUtils.Evaluator(['1_Pronacio', '2_Neutralis', '3_Szupinacio'])\n",
    "evaluator.evaluate(np.argmax(y_true, axis=1), np_baselinePredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de436abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSimpleCNN1 = models.simpleCNNModel()\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=config.MODEL_SAVE_PATH,\n",
    "                                                    save_best_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ae8802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 17:18:39.082344: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "2025-12-13 17:18:39.796408: I external/local_xla/xla/service/service.cc:168] XLA service 0x766871ba67f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-13 17:18:39.796465: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-12-13 17:18:39.807692: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765646319.895377   92140 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - ETA: 0s - loss: 1.4073 - accuracy: 0.1562 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m class_weights = {\n\u001b[32m      2\u001b[39m     \u001b[32m0\u001b[39m: \u001b[32m1.0\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[32m1\u001b[39m: \u001b[32m1.0\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[32m2\u001b[39m: \u001b[32m146\u001b[39m/\u001b[32m54\u001b[39m  \u001b[38;5;66;03m# kb. 2.7-szer nagyobb súly\u001b[39;00m\n\u001b[32m      5\u001b[39m }\n\u001b[32m      6\u001b[39m modelSimpleCNN1.compile(\n\u001b[32m      7\u001b[39m     optimizer=tf.keras.optimizers.Adam(learning_rate=\u001b[32m0.001\u001b[39m),\n\u001b[32m      8\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m history = \u001b[43mmodelSimpleCNN1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:1856\u001b[39m, in \u001b[36mModel.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[39m\n\u001b[32m   1840\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_eval_data_handler\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1841\u001b[39m     \u001b[38;5;28mself\u001b[39m._eval_data_handler = data_adapter.get_data_handler(\n\u001b[32m   1842\u001b[39m         x=val_x,\n\u001b[32m   1843\u001b[39m         y=val_y,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1854\u001b[39m         pss_evaluation_shards=\u001b[38;5;28mself\u001b[39m._pss_evaluation_shards,\n\u001b[32m   1855\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1856\u001b[39m val_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1859\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1861\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1863\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1864\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1865\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1866\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1868\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1869\u001b[39m val_logs = {\n\u001b[32m   1870\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval_\u001b[39m\u001b[33m\"\u001b[39m + name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs.items()\n\u001b[32m   1871\u001b[39m }\n\u001b[32m   1872\u001b[39m epoch_logs.update(val_logs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:2296\u001b[39m, in \u001b[36mModel.evaluate\u001b[39m\u001b[34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[39m\n\u001b[32m   2292\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m tf.profiler.experimental.Trace(\n\u001b[32m   2293\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, step_num=step, _r=\u001b[32m1\u001b[39m\n\u001b[32m   2294\u001b[39m             ):\n\u001b[32m   2295\u001b[39m                 callbacks.on_test_batch_begin(step)\n\u001b[32m-> \u001b[39m\u001b[32m2296\u001b[39m                 logs = \u001b[43mtest_function_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2297\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2298\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2299\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2300\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2301\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2303\u001b[39m logs = tf_utils.sync_to_numpy_or_python_type(logs)\n\u001b[32m   2304\u001b[39m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:4108\u001b[39m, in \u001b[36m_TestFunction.run_step\u001b[39m\u001b[34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[39m\n\u001b[32m   4107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     tmp_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data_handler.should_sync:\n\u001b[32m   4110\u001b[39m         context.async_wait()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    829\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    834\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    835\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:918\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    912\u001b[39m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[32m    913\u001b[39m   filtered_flat_args = (\n\u001b[32m    914\u001b[39m       \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn.function_type.unpack_inputs(\n\u001b[32m    915\u001b[39m           bound_args\n\u001b[32m    916\u001b[39m       )\n\u001b[32m    917\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    919\u001b[39m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[32m    924\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1319\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1321\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1322\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1323\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1324\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1325\u001b[39m     args,\n\u001b[32m   1326\u001b[39m     possible_gradient_type,\n\u001b[32m   1327\u001b[39m     executing_eagerly)\n\u001b[32m   1328\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1486\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1484\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1485\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1486\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1488\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1491\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1494\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1495\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1496\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1500\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1501\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "class_weights = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 146/54  # kb. 2.7-szer nagyobb súly\n",
    "}\n",
    "modelSimpleCNN1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "history = modelSimpleCNN1.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,\n",
    "    callbacks=[cp_callback],\n",
    "    verbose=1,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656747e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 1s - loss: 1.1232 - accuracy: 0.4205 - 713ms/epoch - 238ms/step\n",
      "Untrained model, accuracy: 42.05%\n"
     ]
    }
   ],
   "source": [
    "testModel = models.simpleCNNModel()\n",
    "testModel.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "loss, acc = testModel.evaluate(test_dataset, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19087d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 1s - loss: 1.0609 - accuracy: 0.3523 - 537ms/epoch - 179ms/step\n",
      "Restored model, accuracy: 35.23%\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "testModel.load_weights(config.MODEL_SAVE_PATH)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = testModel.evaluate(test_dataset, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f0c7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",   # inkrementális → bayes jobb, mint grid\n",
    "    \"metric\": {\n",
    "        \"name\": \"val_accuracy\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"weifht_decay\": {\n",
    "            \"values\": [0.0, 1e-4, 1e-3]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [1e-4, 3e-4, 1e-3]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [32, 64]\n",
    "        },\n",
    "        \"conv1_filters\": {\n",
    "            \"values\": [32, 64, 128]\n",
    "        },\n",
    "        \"conv2_filters\": {\n",
    "            \"values\": [32, 64, 128]\n",
    "        },\n",
    "        \"dense_filters\": {\n",
    "            \"values\": [64]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8599526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Input, MaxPool2D, GlobalAveragePooling2D, Dense\n",
    "\n",
    "\n",
    "class_weights = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 146/54  # kb. 2.7-szer nagyobb súly\n",
    "}\n",
    "\n",
    "def build_model(config):\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(128,128,3)),\n",
    "\n",
    "        Conv2D(config.conv1_filters, 3, activation='relu'),\n",
    "        MaxPool2D(),\n",
    "\n",
    "        Conv2D(config.conv2_filters, 3, activation='relu'),\n",
    "        MaxPool2D(),\n",
    "\n",
    "        GlobalAveragePooling2D(),\n",
    "\n",
    "        Dense(config.dense_filters, activation='relu'),\n",
    "\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            weight_decay=config.weifht_decay,\n",
    "            learning_rate=config.learning_rate\n",
    "            ),\n",
    "        loss=metricsUtils.OrdinalDistanceLoss(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d61ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<metricsUtils.OrdinalDistanceLoss at 0x7971ba046610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricsUtils.OrdinalDistanceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2834b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sweep():\n",
    "    wandb.init()\n",
    "    configWandb = wandb.config\n",
    "\n",
    "    model = build_model(configWandb)\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=20,  # inkrementális → nem 50!\n",
    "        callbacks=[\n",
    "            wandb.keras.WandbMetricsLogger(),\n",
    "            wandb.keras.WandbModelCheckpoint(filepath=config.MODEL_SAVE_PATH,monitor=\"val_accuracy\",save_best_only=True)\n",
    "            ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa36aafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: skl7nvc9\n",
      "Sweep URL: https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 14ib1xvs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m0322sagibenedek\u001b[0m (\u001b[33mvitmma19\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_105825-14ib1xvs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/14ib1xvs' target=\"_blank\">celestial-sweep-1</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/14ib1xvs' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/14ib1xvs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 10:58:27.750189: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "2025-12-14 10:58:30.722042: I external/local_xla/xla/service/service.cc:168] XLA service 0x796fd23b2ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-14 10:58:30.722085: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-12-14 10:58:30.769438: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765709911.123216   30839 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 10s 16ms/step - loss: 0.5794 - accuracy: 0.3458 - val_loss: 0.6989 - val_accuracy: 0.3939\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.4112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 4s 12ms/step - loss: 0.5768 - accuracy: 0.4112 - val_loss: 0.6991 - val_accuracy: 0.4545\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 4s 13ms/step - loss: 0.5761 - accuracy: 0.4019 - val_loss: 0.6977 - val_accuracy: 0.3030\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 5s 12ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6981 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5761 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 4s 12ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6980 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 3s 9ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6977 - val_accuracy: 0.3030\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5752 - accuracy: 0.4346 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 4s 12ms/step - loss: 0.5748 - accuracy: 0.4393 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 3s 9ms/step - loss: 0.5746 - accuracy: 0.4393 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 5s 20ms/step - loss: 0.5741 - accuracy: 0.4393 - val_loss: 0.6976 - val_accuracy: 0.3030\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5738 - accuracy: 0.4346 - val_loss: 0.6975 - val_accuracy: 0.3333\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 3s 8ms/step - loss: 0.5730 - accuracy: 0.4439 - val_loss: 0.6967 - val_accuracy: 0.2727\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5716 - accuracy: 0.4439 - val_loss: 0.6963 - val_accuracy: 0.1818\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5698 - accuracy: 0.4860 - val_loss: 0.6947 - val_accuracy: 0.3333\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5672 - accuracy: 0.4393 - val_loss: 0.6920 - val_accuracy: 0.4545\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5641 - accuracy: 0.4112 - val_loss: 0.6879 - val_accuracy: 0.4545\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5611 - accuracy: 0.3972 - val_loss: 0.6839 - val_accuracy: 0.4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▄▄▅▅▅▅▅▅▅▆▆▆▅▆▆█▆▄▄</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▇▆▇▇▆▇▆▆▆▆▆▆▆▅▄▃▂▁</td></tr><tr><td>epoch/val_accuracy</td><td>▆█▄▄▄▄▄▄▄▄▄▄▄▅▃▁▅███</td></tr><tr><td>epoch/val_loss</td><td>██▇█▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.3972</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.0003</td></tr><tr><td>epoch/loss</td><td>0.56112</td></tr><tr><td>epoch/val_accuracy</td><td>0.45455</td></tr><tr><td>epoch/val_loss</td><td>0.6839</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-1</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/14ib1xvs' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/14ib1xvs</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_105825-14ib1xvs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 32w3e40h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_105941-32w3e40h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/32w3e40h' target=\"_blank\">vague-sweep-2</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/32w3e40h' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/32w3e40h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  5/214 [..............................] - ETA: 3s - loss: 0.9855 - accuracy: 0.6000      WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 0.0089s). Check your callbacks.\n",
      "214/214 [==============================] - 7s 22ms/step - loss: 0.5800 - accuracy: 0.3879 - val_loss: 0.6973 - val_accuracy: 0.1818\n",
      "Epoch 2/20\n",
      "211/214 [============================>.] - ETA: 0s - loss: 0.5755 - accuracy: 0.4265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5768 - accuracy: 0.4252 - val_loss: 0.6979 - val_accuracy: 0.3030\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5761 - accuracy: 0.4252 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.5758 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 5s 17ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5762 - accuracy: 0.4252 - val_loss: 0.6971 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6976 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5756 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 5s 20ms/step - loss: 0.5751 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5753 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5751 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5753 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5751 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁███████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▂▂▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁███████████████████</td></tr><tr><td>epoch/val_loss</td><td>▂█▇▃▄▄▁▅▄▃▂▃▁▂▄▂▃▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.42523</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.57499</td></tr><tr><td>epoch/val_accuracy</td><td>0.30303</td></tr><tr><td>epoch/val_loss</td><td>0.69754</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vague-sweep-2</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/32w3e40h' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/32w3e40h</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_105941-32w3e40h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l3k3fwww with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_110054-l3k3fwww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/l3k3fwww' target=\"_blank\">cool-sweep-3</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/l3k3fwww' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/l3k3fwww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "214/214 [==============================] - 4s 13ms/step - loss: 0.5777 - accuracy: 0.4252 - val_loss: 0.6994 - val_accuracy: 0.3030\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5768 - accuracy: 0.4252 - val_loss: 0.6984 - val_accuracy: 0.3030\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 4s 15ms/step - loss: 0.5761 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6979 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5753 - accuracy: 0.4252 - val_loss: 0.6977 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 4s 14ms/step - loss: 0.5756 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 5s 11ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6976 - val_accuracy: 0.3030\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.5749 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5747 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5742 - accuracy: 0.4252 - val_loss: 0.6970 - val_accuracy: 0.3030\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5739 - accuracy: 0.4439 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5727 - accuracy: 0.4439 - val_loss: 0.6953 - val_accuracy: 0.3333\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5714 - accuracy: 0.4346 - val_loss: 0.6945 - val_accuracy: 0.3333\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5689 - accuracy: 0.4953 - val_loss: 0.6906 - val_accuracy: 0.3636\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 4s 16ms/step - loss: 0.5657 - accuracy: 0.4393 - val_loss: 0.6936 - val_accuracy: 0.4545\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5609 - accuracy: 0.4159 - val_loss: 0.6857 - val_accuracy: 0.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃█▃▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>██▇▇▇▇▇▇▇▇▇▇▇▇▆▆▅▄▃▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄█▇</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▄▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.41589</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.0003</td></tr><tr><td>epoch/loss</td><td>0.56093</td></tr><tr><td>epoch/val_accuracy</td><td>0.42424</td></tr><tr><td>epoch/val_loss</td><td>0.68569</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cool-sweep-3</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/l3k3fwww' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/l3k3fwww</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_110054-l3k3fwww/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ymwi22eh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_110204-ymwi22eh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/ymwi22eh' target=\"_blank\">sunny-sweep-4</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/ymwi22eh' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/ymwi22eh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "214/214 [==============================] - 7s 22ms/step - loss: 0.5783 - accuracy: 0.3832 - val_loss: 0.6991 - val_accuracy: 0.4545\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5769 - accuracy: 0.3738 - val_loss: 0.6987 - val_accuracy: 0.4242\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5762 - accuracy: 0.4019 - val_loss: 0.6979 - val_accuracy: 0.3030\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5763 - accuracy: 0.4252 - val_loss: 0.6980 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5759 - accuracy: 0.4252 - val_loss: 0.6979 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 4s 16ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6980 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5756 - accuracy: 0.4252 - val_loss: 0.6976 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5751 - accuracy: 0.4252 - val_loss: 0.6977 - val_accuracy: 0.3030\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5756 - accuracy: 0.4299 - val_loss: 0.6982 - val_accuracy: 0.3333\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5756 - accuracy: 0.4439 - val_loss: 0.6973 - val_accuracy: 0.3333\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5751 - accuracy: 0.4533 - val_loss: 0.6973 - val_accuracy: 0.3333\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 4s 14ms/step - loss: 0.5751 - accuracy: 0.4533 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5748 - accuracy: 0.4533 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.5748 - accuracy: 0.4579 - val_loss: 0.6975 - val_accuracy: 0.3333\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 5s 22ms/step - loss: 0.5750 - accuracy: 0.4579 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5743 - accuracy: 0.4626 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5740 - accuracy: 0.4579 - val_loss: 0.6962 - val_accuracy: 0.3333\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5737 - accuracy: 0.4579 - val_loss: 0.6961 - val_accuracy: 0.3636\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5734 - accuracy: 0.4439 - val_loss: 0.6955 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▂▁▃▅▅▅▅▅▅▅▇▇▇▇█████▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▅▅▄▄▄▃▄▄▃▃▃▃▃▂▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>█▇▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▄▂</td></tr><tr><td>epoch/val_loss</td><td>█▇▆▆▆▆▅▅▅▆▅▅▄▄▅▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.44393</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.5734</td></tr><tr><td>epoch/val_accuracy</td><td>0.33333</td></tr><tr><td>epoch/val_loss</td><td>0.69553</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-sweep-4</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/ymwi22eh' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/ymwi22eh</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_110204-ymwi22eh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i87ds8qa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_110316-i87ds8qa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/i87ds8qa' target=\"_blank\">dashing-sweep-5</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/i87ds8qa' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/i87ds8qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "214/214 [==============================] - 5s 13ms/step - loss: 0.5805 - accuracy: 0.3972 - val_loss: 0.6983 - val_accuracy: 0.3030\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5766 - accuracy: 0.4252 - val_loss: 0.6981 - val_accuracy: 0.3030\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5758 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 5s 20ms/step - loss: 0.5753 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5753 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5753 - accuracy: 0.4252 - val_loss: 0.6971 - val_accuracy: 0.3030\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5759 - accuracy: 0.4252 - val_loss: 0.6976 - val_accuracy: 0.3030\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5751 - accuracy: 0.4252 - val_loss: 0.6976 - val_accuracy: 0.3030\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6976 - val_accuracy: 0.3030\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5749 - accuracy: 0.4252 - val_loss: 0.6971 - val_accuracy: 0.3030\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6980 - val_accuracy: 0.3030\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5747 - accuracy: 0.4252 - val_loss: 0.6984 - val_accuracy: 0.3030\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5737 - accuracy: 0.4299 - val_loss: 0.6964 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5734 - accuracy: 0.4299 - val_loss: 0.6985 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██</td></tr><tr><td>epoch/val_loss</td><td>█▇▄▅▅▄▄▅▃▅▅▅▅▅▆▄▆█▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.42991</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.57339</td></tr><tr><td>epoch/val_accuracy</td><td>0.33333</td></tr><tr><td>epoch/val_loss</td><td>0.69846</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dashing-sweep-5</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/i87ds8qa' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/i87ds8qa</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_110316-i87ds8qa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: juhdzd4s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_110432-juhdzd4s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/juhdzd4s' target=\"_blank\">royal-sweep-6</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/juhdzd4s' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/juhdzd4s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "214/214 [==============================] - 5s 13ms/step - loss: 0.5782 - accuracy: 0.4019 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 2/20\n",
      "212/214 [============================>.] - ETA: 0s - loss: 0.5721 - accuracy: 0.4057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5761 - accuracy: 0.4019 - val_loss: 0.6979 - val_accuracy: 0.3333\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6981 - val_accuracy: 0.3030\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5756 - accuracy: 0.4252 - val_loss: 0.6977 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5751 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5753 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 5s 20ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 4s 16ms/step - loss: 0.5750 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 5s 18ms/step - loss: 0.5749 - accuracy: 0.4252 - val_loss: 0.6971 - val_accuracy: 0.3030\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 4s 13ms/step - loss: 0.5749 - accuracy: 0.4252 - val_loss: 0.6970 - val_accuracy: 0.3030\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5748 - accuracy: 0.4252 - val_loss: 0.6969 - val_accuracy: 0.3030\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 4s 15ms/step - loss: 0.5748 - accuracy: 0.4252 - val_loss: 0.6968 - val_accuracy: 0.3030\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5747 - accuracy: 0.4252 - val_loss: 0.6967 - val_accuracy: 0.3333\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 4s 14ms/step - loss: 0.5746 - accuracy: 0.4299 - val_loss: 0.6965 - val_accuracy: 0.3333\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 5s 22ms/step - loss: 0.5745 - accuracy: 0.4486 - val_loss: 0.6963 - val_accuracy: 0.3333\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5744 - accuracy: 0.4533 - val_loss: 0.6961 - val_accuracy: 0.3333\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5743 - accuracy: 0.4579 - val_loss: 0.6960 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▇▇█</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁█████</td></tr><tr><td>epoch/val_loss</td><td>▆▇█▇▅▅▅▅▅▅▅▅▄▄▄▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.45794</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.57429</td></tr><tr><td>epoch/val_accuracy</td><td>0.33333</td></tr><tr><td>epoch/val_loss</td><td>0.69597</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-sweep-6</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/juhdzd4s' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/juhdzd4s</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_110432-juhdzd4s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p41ugh0i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_110550-p41ugh0i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/p41ugh0i' target=\"_blank\">confused-sweep-7</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/p41ugh0i' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/p41ugh0i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "214/214 [==============================] - 5s 13ms/step - loss: 0.5811 - accuracy: 0.4206 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5758 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 4s 10ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.5750 - accuracy: 0.4299 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5746 - accuracy: 0.4346 - val_loss: 0.6976 - val_accuracy: 0.3030\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5742 - accuracy: 0.4439 - val_loss: 0.6977 - val_accuracy: 0.3030\n",
      "Epoch 12/20\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.5718 - accuracy: 0.4319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5737 - accuracy: 0.4299 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5725 - accuracy: 0.4346 - val_loss: 0.6958 - val_accuracy: 0.3333\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5695 - accuracy: 0.4673 - val_loss: 0.6937 - val_accuracy: 0.2727\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5661 - accuracy: 0.4766 - val_loss: 0.6928 - val_accuracy: 0.2727\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 5s 19ms/step - loss: 0.5615 - accuracy: 0.4813 - val_loss: 0.6879 - val_accuracy: 0.3030\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5580 - accuracy: 0.4907 - val_loss: 0.6956 - val_accuracy: 0.3636\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5542 - accuracy: 0.4766 - val_loss: 0.6875 - val_accuracy: 0.3333\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5516 - accuracy: 0.4299 - val_loss: 0.6949 - val_accuracy: 0.3636\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5501 - accuracy: 0.4206 - val_loss: 0.6964 - val_accuracy: 0.3939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▂▂▃▂▂▆▇▇█▇▂▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▇▇▇▇▇▇▇▇▆▆▆▅▅▄▃▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▃▃▃▃▃▃▃▃▃▃▃▅▅▁▁▃▆▅▆█</td></tr><tr><td>epoch/val_loss</td><td>████████████▇▅▅▁▇▁▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.42056</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.0003</td></tr><tr><td>epoch/loss</td><td>0.5501</td></tr><tr><td>epoch/val_accuracy</td><td>0.39394</td></tr><tr><td>epoch/val_loss</td><td>0.69643</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-7</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/p41ugh0i' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/p41ugh0i</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_110550-p41ugh0i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y9x6yra3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_110701-y9x6yra3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/y9x6yra3' target=\"_blank\">curious-sweep-8</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/y9x6yra3' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/y9x6yra3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  6/214 [..............................] - ETA: 9s - loss: 0.8199 - accuracy: 0.6667 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_train_batch_end` time: 0.0339s). Check your callbacks.\n",
      "214/214 [==============================] - 4s 14ms/step - loss: 0.5800 - accuracy: 0.3972 - val_loss: 0.6993 - val_accuracy: 0.4545\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5764 - accuracy: 0.3505 - val_loss: 0.6986 - val_accuracy: 0.4242\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5761 - accuracy: 0.4112 - val_loss: 0.6989 - val_accuracy: 0.4545\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 4s 10ms/step - loss: 0.5770 - accuracy: 0.4299 - val_loss: 0.6984 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5757 - accuracy: 0.4252 - val_loss: 0.6983 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5757 - accuracy: 0.4252 - val_loss: 0.6979 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5757 - accuracy: 0.4252 - val_loss: 0.6977 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6982 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5762 - accuracy: 0.4252 - val_loss: 0.6981 - val_accuracy: 0.3030\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5758 - accuracy: 0.4252 - val_loss: 0.6977 - val_accuracy: 0.3030\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5752 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5750 - accuracy: 0.4299 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5749 - accuracy: 0.4346 - val_loss: 0.6972 - val_accuracy: 0.3030\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 0.5746 - accuracy: 0.4393 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5744 - accuracy: 0.4439 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5741 - accuracy: 0.4533 - val_loss: 0.6967 - val_accuracy: 0.3333\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.5739 - accuracy: 0.4533 - val_loss: 0.6964 - val_accuracy: 0.3333\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 4s 14ms/step - loss: 0.5733 - accuracy: 0.4346 - val_loss: 0.6961 - val_accuracy: 0.3636\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5730 - accuracy: 0.4393 - val_loss: 0.6957 - val_accuracy: 0.3333\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.5724 - accuracy: 0.4393 - val_loss: 0.6953 - val_accuracy: 0.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▄▁▅▆▆▆▆▆▆▆▆▆▇▇▇██▇▇▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▄▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▁</td></tr><tr><td>epoch/val_accuracy</td><td>█▇█▁▁▁▁▁▁▁▁▁▁▂▂▂▂▄▂▄</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▆▆▆▅▆▆▅▅▅▄▄▄▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.43925</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.57241</td></tr><tr><td>epoch/val_accuracy</td><td>0.36364</td></tr><tr><td>epoch/val_loss</td><td>0.69526</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-sweep-8</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/y9x6yra3' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/y9x6yra3</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_110701-y9x6yra3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7u4wb50u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_110808-7u4wb50u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/7u4wb50u' target=\"_blank\">silver-sweep-9</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/7u4wb50u' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/7u4wb50u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  5/214 [..............................] - ETA: 7s - loss: 0.9218 - accuracy: 0.6000    WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_train_batch_end` time: 0.0258s). Check your callbacks.\n",
      "214/214 [==============================] - 4s 13ms/step - loss: 0.5873 - accuracy: 0.4112 - val_loss: 0.6981 - val_accuracy: 0.3030\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5760 - accuracy: 0.4252 - val_loss: 0.6983 - val_accuracy: 0.3030\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 4s 10ms/step - loss: 0.5761 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5756 - accuracy: 0.4252 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6974 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6977 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5754 - accuracy: 0.4252 - val_loss: 0.6980 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5755 - accuracy: 0.4252 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5761 - accuracy: 0.4252 - val_loss: 0.6980 - val_accuracy: 0.3030\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5808 - accuracy: 0.4206 - val_loss: 0.7066 - val_accuracy: 0.3030\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5769 - accuracy: 0.4252 - val_loss: 0.6993 - val_accuracy: 0.3030\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5747 - accuracy: 0.4299 - val_loss: 0.6990 - val_accuracy: 0.3030\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 5s 11ms/step - loss: 0.5737 - accuracy: 0.4252 - val_loss: 0.7000 - val_accuracy: 0.3030\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5735 - accuracy: 0.4206 - val_loss: 0.7046 - val_accuracy: 0.3030\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5681 - accuracy: 0.4346 - val_loss: 0.7005 - val_accuracy: 0.3030\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5695 - accuracy: 0.4252 - val_loss: 0.7027 - val_accuracy: 0.3030\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5654 - accuracy: 0.4299 - val_loss: 0.7016 - val_accuracy: 0.3030\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5627 - accuracy: 0.4299 - val_loss: 0.7011 - val_accuracy: 0.3030\n",
      "Epoch 20/20\n",
      "208/214 [============================>.] - ETA: 0s - loss: 0.5595 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 3s 11ms/step - loss: 0.5612 - accuracy: 0.4393 - val_loss: 0.7004 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▄▄▄▄▄▄▄▄▄▃▄▆▄▃▇▄▆▆█</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▅▅▅▅▅▅▅▅▆▅▅▄▄▃▃▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>epoch/val_loss</td><td>▂▂▁▁▁▁▁▁▁▁█▂▂▃▆▃▅▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.43925</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.56124</td></tr><tr><td>epoch/val_accuracy</td><td>0.33333</td></tr><tr><td>epoch/val_loss</td><td>0.70039</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sweep-9</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/7u4wb50u' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/7u4wb50u</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_110808-7u4wb50u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pf0bp9gw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweifht_decay: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebook/wandb/run-20251214_110913-pf0bp9gw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/pf0bp9gw' target=\"_blank\">rose-sweep-10</a></strong> to <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/sweeps/skl7nvc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/pf0bp9gw' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/pf0bp9gw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  5/214 [..............................] - ETA: 11s - loss: 0.9748 - accuracy: 0.8000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0429s). Check your callbacks.\n",
      "214/214 [==============================] - 4s 12ms/step - loss: 0.5806 - accuracy: 0.4112 - val_loss: 0.7005 - val_accuracy: 0.3030\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.5772 - accuracy: 0.4252 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5761 - accuracy: 0.4252 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5753 - accuracy: 0.4252 - val_loss: 0.6978 - val_accuracy: 0.3030\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5757 - accuracy: 0.4252 - val_loss: 0.6979 - val_accuracy: 0.3030\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.5753 - accuracy: 0.4252 - val_loss: 0.6973 - val_accuracy: 0.3030\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.5749 - accuracy: 0.4346 - val_loss: 0.6975 - val_accuracy: 0.3030\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5751 - accuracy: 0.4439 - val_loss: 0.6980 - val_accuracy: 0.3030\n",
      "Epoch 9/20\n",
      "205/214 [===========================>..] - ETA: 0s - loss: 0.5653 - accuracy: 0.4293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5744 - accuracy: 0.4252 - val_loss: 0.6966 - val_accuracy: 0.3333\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5744 - accuracy: 0.4206 - val_loss: 0.6979 - val_accuracy: 0.3333\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5724 - accuracy: 0.4346 - val_loss: 0.6961 - val_accuracy: 0.3030\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5690 - accuracy: 0.4673 - val_loss: 0.6925 - val_accuracy: 0.2727\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5650 - accuracy: 0.5000 - val_loss: 0.6893 - val_accuracy: 0.3030\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5597 - accuracy: 0.4860 - val_loss: 0.6882 - val_accuracy: 0.3030\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 4s 9ms/step - loss: 0.5566 - accuracy: 0.4813 - val_loss: 0.6806 - val_accuracy: 0.2727\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5538 - accuracy: 0.4907 - val_loss: 0.6965 - val_accuracy: 0.3333\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5515 - accuracy: 0.4766 - val_loss: 0.6940 - val_accuracy: 0.3333\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5504 - accuracy: 0.4673 - val_loss: 0.6966 - val_accuracy: 0.3333\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5494 - accuracy: 0.4673 - val_loss: 0.6963 - val_accuracy: 0.3333\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5487 - accuracy: 0.4673 - val_loss: 0.6967 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▂▂▂▂▃▄▂▂▃▅█▇▇▇▆▅▅▅</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▇▇▇▇▇▇▇▇▆▅▅▃▃▂▂▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▅▅▅▅▅▅▅▅██▅▁▅▅▁█████</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▇▇▇▇▇▇▇▆▅▄▄▁▇▆▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.46729</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.0003</td></tr><tr><td>epoch/loss</td><td>0.54868</td></tr><tr><td>epoch/val_accuracy</td><td>0.33333</td></tr><tr><td>epoch/val_loss</td><td>0.69672</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-sweep-10</strong> at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental/runs/pf0bp9gw' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental/runs/pf0bp9gw</a><br> View project at: <a href='https://wandb.ai/vitmma19/better-cnn-incremental' target=\"_blank\">https://wandb.ai/vitmma19/better-cnn-incremental</a><br>Synced 4 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251214_110913-pf0bp9gw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"better-cnn-incremental\")\n",
    "wandb.agent(sweep_id, function=train_sweep, count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
